---
title: "RM ANOVA: Two-way and Graphing"
geometry: margin=.5in
header-includes:
- \usepackage{amsmath}
output:
  pdf_document:
    highlight: default
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    toc: yes
    toc_depth: '4'
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning =  FALSE)
knitr::opts_chunk$set(fig.width=4.75)
knitr::opts_chunk$set(fig.height=2.75)
knitr::opts_chunk$set(fig.align='center') 
knitr::opts_chunk$set(fig.pos = 'H')
knitr::opts_chunk$set(results='hold') 
```

\pagebreak

# 2 Repeated Factors
> In the previous class, we saw eating some small amount of chocolate increased the class increase fixation to the lecture. However, because we took the average fixation over the course the class, we are not sure how the long the effect lasts.  Further, students may habituate to chocolate over time. To understand how chocolate modulated attention, we design a 4x3 study fully within-subjects design. During the first 20 min of class Graduate students' eyes were tracked we measured the mean fixation time student's eyes are on the screen (in seconds per glance). In the next 20 mins, graduate students were given a fun-sized Snickers to encourage them to pay attention.  However, we are not sure how to "encourage" students. We could give them more snickers the more time they spend looking at the screen (i.e., Positive reinforcement) or try to encourage them to look back at the screen when they take their eyes off it too long (i.e., Negative reinforcement).  The machine continued spitting out Snickers for the rest of the class period, depending on the condition they were in during that lecture.  Finally, we need a control condition to understand how attention is modulated throughout an 80-minute lecture (No reinforcement). The mean fixation time was recorded and reported at the end of every 20 min interval.  The order in which students received No, Positive, Negative reinforcement was counterbalanced between the topics of the lecture ("Power Analysis," "Bootstrapping Theory," and "Probability Theory," which were matched based on the thrilling-ness of topic). We will simulated $n$ = 9 students. If classical learning theory is correct, when students are positively rewarded they will pay more attention to the lecture and when they are negatively rewarded the will learn they get more chocolate the less they pay attention. However, if graduate students are intrinsically motivated, negative reinforcement might not adversely affect attention as strongly as classical learning theory predicts. Further, we expect fatigue to set in and cause reductions of attention in all conditions.        

```{r, echo=FALSE}
library(MASS)
library(tidyr)
library(dplyr)
set.seed(9)
n = 9; 
## means
M1A=11; M2A=15; M3A=14; M4A=7
M1B=11; M2B=15; M3B=9; M4B=7
M1C=11; M2C=11; M3C=7; M4C=7
## Generate Cov matrix
# create k x k matrix populated with sigma
sigma=9
sigma.mat <- rep(sigma, 4*3)
S <- matrix(sigma.mat, ncol=length(sigma.mat), nrow=length(sigma.mat))
rho=.9
# compute covariance between measures
Sigma <- t(S) * S * rho  
# put the variances on the diagonal 
diag(Sigma) <- sigma^2  

Simulation = mvrnorm(n=n, mu=c(M1A,M2A,M3A,M4A,
                            M1B,M2B,M3B,M4B,
                            M1C,M2C,M3C,M4C), Sigma=Sigma, empirical=FALSE)

DataSim1<-data.frame(Simulation)
DataSim2<-gather(DataSim1,key = "Key", value = "Fixation",X1:X12)
DataSim2$ID<-as.factor(rep(seq(1:n),12))
DataSim2$Time<-as.factor(rep(c("0-19", "20-39","40-59","60-79"),each=9))
DataSim2$Reinforcement<-as.factor(rep(c("Positive", "Negative", "None"),each=9*4))
DataSim2$Time<-factor(DataSim2$Time, 
       levels=c("0-19", "20-39","40-59","60-79"),
       labels=c("0-19", "20-39","40-59","60-79"))
DataSim2$Reinforcement<-factor(DataSim2$Reinforcement, 
       levels=c("Positive", "Negative", "None"),
       labels=c("Positive", "Negative", "None"))
DataSim2$Fixation<-round(DataSim2$Fixation,0)
DataSim2$Fixation<-if_else(DataSim2$Fixation < 0,0,DataSim2$Fixation)
```


## Plot of Simulation
### Spaghetti Plot
Each line represents a person's score across conditions

```{r, echo=FALSE,fig.width=6}
library(ggplot2)
theme_set(theme_bw(base_size = 12, base_family = "")) 

Spaghetti.1 <-ggplot(data = DataSim2, aes(x = Time, y=Fixation, group=ID))+
  facet_grid(~Reinforcement)+
  scale_y_continuous(limits=c(0,30),breaks = seq(0,30,2))+
  geom_point(aes(colour = ID))+
  geom_line(aes(colour = ID))+
  ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "none")
Spaghetti.1
```

### Means plot 
We will plot them as Lines with no error bars for now (plotting error in RM designs is different, and we will come back to that later).

```{r, echo=FALSE,fig.width=6}
theme_set(theme_bw(base_size = 12, base_family = "")) 

Means.Table<-
  DataSim2 %>% 
  group_by(Time,Reinforcement) %>%
  summarise(Fix.Mean=mean(Fixation))
  

Means.Lines <-ggplot(data = Means.Table, aes(x = Time, y=Fix.Mean, group=Reinforcement))+
  scale_y_continuous(limits=c(0,20),breaks = seq(0,20,2))+
  geom_line(aes(colour = Reinforcement), size=2)+
  ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "right")
Means.Lines
```

Are there main-effects for Time or Reinforcement and does Time and Reinforcement interact? 

## 2-Way RM ANOVA logic
Just like two-way ANOVA, in the two-way RM ANOVA, you have two Main-effects and an interaction. However, the errors terms are more complicated.   
Just as in one-way RM ANOVA we will find the variance due to the individual difference, which we can estimate by calculating the row sum, which are the sums of each subject's scores. 

\pagebreak

### One-way RM ANOVA Table With the formulas (conceptually simplified)

| Source                   | SS                                        | DF           | MS  | F   |
| :----------------------- | :---------------------------------------- | :----------- | :-- | :-- |
| $RM_1$                   | $nSS_{Treat\,1\,cell\,means}$             | $c-1$        | $\frac{SS_{RM}}{df_{RM}}$ | $\frac{MS_{RM_1}}{MS_{E_1}}$ |
| Within                   | $\displaystyle \sum SS_{within}$          |              |     |     |
| $\,Subject\,[Sub]$       | $\frac{1}{c} SS_{subjects:\, rows\,sums}$ | $n-1$        | $\frac{SS_{sub}}{df_{sub}}$ |     |
| $\,Error [Sub\,x\,RM_1]$ | $SS_W-SS_{sub}$                           | $(n-1)(c-1)$ | $\frac{SS_{E_1}}{df_{E_1}}$ |     |
| Total                    | $SS_{scores}$                             | $N-1$        |     |     |

Note: $SS_{sub} + SS_E = SS_W$ & $SS_B + SS_W = SS_T$ & $df_B + df_W = df_T$

### Two-way RM ANOVA Table With the formulas (conceptually simplified)

Source        | SS                  | DF          | MS   | F
--------------|---------------------|-------------|------|---
$RM_1$ | $c_2nSS_{treat\,1\,cell\,means}$ | $c_1-1$| $\frac{SS_{RM_1}}{df_{RM_1}}$ | $\frac{MS_{RM_1}}{MS_{E_1}}$
$RM_2$ | $c_1nSS_{treat\,2\,cell\,means}$ | $c_2-1$| $\frac{SS_{RM_2}}{df_{RM_2}}$ |$\frac{MS_{RM_2}}{MS_{E_2}}$
$RM_{1x2}$ | $nSS_{all\,treat\,cells}-SS_{RM_1} - SS_{RM_2}$ | $(c_1-1)(c_2-1)$| $\frac{SS_{RM_{1x2}}}{df_{RM_{1x2}}}$ | $\frac{MS_{RM_{1x2}}}{MS_{E_{1x2}}}$
Within  | $\displaystyle \sum SS_{within}$     |   
$\,Subject\,[Sub]$  | $\frac{1}{c_1}\frac{1}{c_2} SS_{subjects:\, rows\,sums}$     | $n-1$     | $\frac{SS_{sub}}{df_{sub}}$ | 
$\,Error_1 [Sub\,x\,RM_1]$  | $SS_{treat\,1\,cells}-SS_{RM_1}-SS_{sub}$     | $(n-1)(c_1-1)$     | $\frac{SS_{E_1}}{df_{E_1}}$ | 
$\,Error_2 [Sub\,x\,RM_2]$  | $SS_{treat\,2\,cells}-SS_{RM_2}-SS_{sub}$     | $(n-1)(c_2-1)$     | $\frac{SS_{E_2}}{df_{E_2}}$ | 
$\,Error_{1x2} [Sub\,x\,RM_{1x2}]$  | $SS_T-SS_{RM_1}-SS_{RM_2}-SS_{RM_{1x2}}-SS_{sub}-SS_{E_1}-SS_{E_2}$     | $(n-1)(c_1-1)(c_2-1)$     | $\frac{SS_{E_{1x2}}}{df_{E_{1x2}}}$ | 
Total   | $SS_{scores}$      | $N-1$ 

Note: $SS_{sub} + SS_E = SS_W$ & $SS_B + SS_W = SS_T$ & $df_B + df_W = df_T$


#### Explained vs. Unexplained terms

**Explained:** 

$SS_{RM_1}$ = caused by treatment 1
$SS_{RM_2}$ = caused by treatment 2
$SS_{RM_{1x2}}$ = caused by treatment 1 x treatment 2
$SS_{sub}$ = individual differences (you do not know why people are different from each other, but you can parse this variance, so we *explained it*).

**Unexplained:** 

$SS_{E_1}$ = Noise due to ${RM_1}$  
$SS_{E_2}$ = Noise due to ${RM_1}$     
$SS_{E_{1x2}}$ = Noise due to $RM_{1x2}$   

## R ANOVA Calculations
### R Defaults
-`afex` calculates the RM ANOVA for us and it will automatically correct for sphericity violations. 
- Error(Subject ID/RM Factor 1 X RM Factor 2): This tells the afex that subjects vary as function RM conditions.  
- It reports $\eta_g^2$ assuming a manipulated treatment.

```{r}
library(afex)
Model.1<-aov_car(Fixation~ Time*Reinforcement + Error(ID/Time*Reinforcement), 
        data = DataSim2)
Model.1
```

### Assumptions
#### Sphericity
Same as one-way ANOVA, except we should examine Mauchly's test for Sphericity on each term (that has more than 2 levels)

```{r}
aov_car(Fixation~ Time*Reinforcement + Error(ID/Time*Reinforcement), 
        data = DataSim2, return="univariate")
```

#### Covariance Matrix 

For most RM ANOVAs we assume Compound Symmetry: 

$$
\mathbf{Cov} = \sigma^2\left[\begin{array}
          {rrrr}
          1 & \rho & \rho & \rho  \\
          \rho & 1 & \rho & \rho  \\
          \rho & \rho & 1 & \rho  \\
          \rho & \rho & \rho & 1\\
          \end{array}\right]
$$ 

However, as in the case of the study that we examined today, people do not always behave over time the with the same correction over time. This about a longitudinal study where time can be over weeks or months.  Time introduces a strange problem called 'auto-regression' (auto-correlation), i.e., what I do now impacts what I do next (remember Time cannot be counterbalanced). 

There are many other types of Covariance Matrices that you can assume, but not in RM ANOVA. RM ANOVA is a special case of the linear mixed model. Next semester will explore linear mixed models a little, which are better for dealing with time. 

Here is an example of Covariance Matrix specifically meant for time: First Order Autoregressive AR(1): 

$$
\mathbf{Cov} = \sigma^2\left[\begin{array}
          {rrrr}
          1 & \rho & \rho^2 & \rho^3  \\
          \rho & 1 & \rho & \rho^2  \\
          \rho^2 & \rho & 1 & \rho  \\
          \rho^3 & \rho^2 & \rho & 1\\
          \end{array}\right]
$$ 


# Plot Results
## Problems with Error Bars
Within-subject designs present a few problems when plotting "error" for a visual approximation of significance. The main problem is that we are plotting the error within each cell (the individual differences). The gray band over the data is the 95%CI. 

```{r, echo=FALSE,fig.width=6}
theme_set(theme_bw(base_size = 12, base_family = "")) 

Means.Table<-
  DataSim2 %>% 
  group_by(Time,Reinforcement) %>%
  summarise(n=n(),
            Means=mean(Fixation),
            SE=sd(Fixation)/n^.5,
            ci = qt(1 - (0.05 / 2), n - 1) * SE)

Means.Between.CI <-ggplot(data = Means.Table, aes(x = Time, y=Means))+
  facet_grid(~Reinforcement)+
  scale_y_continuous(limits=c(0,30),breaks = seq(0,30,2))+
  geom_line(data = DataSim2, aes(x = Time, y=Fixation, group=ID, colour = ID), size=1)+
  geom_line(group=1, size=1, alpha=.3)+
  geom_ribbon(data = Means.Table, aes(ymin=Means-ci, ymax=Means+ci), group=1, alpha=.5)+
    ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "right")
Means.Between.CI
```

### Non-Corrected Error Bars
When we collapse the lines and plot the CIs, we can see they completely overlap. We might conclude there are no significant differences between the groups. But again the problem is we have not removed the individual differences (which we can account for).  

```{r, echo=FALSE,fig.width=6}
Means.BT.SE <-ggplot(data = Means.Table, aes(x = Time, y=Means, group=Reinforcement))+
  scale_y_continuous(breaks = seq(0,20,2))+
  geom_line(aes(colour = Reinforcement), size=2)+
    geom_ribbon(aes(ymin=Means-ci, ymax=Means+ci, fill=Reinforcement), alpha=.5)+
  ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "right")
Means.BT.SE
```

### Within Errors Bars: CI
We will use Cousineau-Morey Corrected error bars which remove individual differences (see Morey, 2008 Figure 1 for visual of the difference between error bar types & Cousineau & O'Brien, 2014 for a review on the theory).  First, we center each subject (remove their means across all conditions). This makes each person's mean = 0 (across conditions). Next, we recalculate the standard error or confidence interval on these centered means.  Finally, we apply a correction to correct for bias (this method underestimates the variance). Correction = $\sqrt{\frac{J}{J-1}}$, where J = number of within factors. Correct SE for plotting = SE (or CI) on centered data * Correction.   

This is a lot of steps, so Cousineau & O'Brien (2014) provide some sample code. Also, there is a function built into the `afex` package that will produce this correction (see https://www.rdocumentation.org/packages/afex/versions/0.22-1/topics/afex_plot). However, I find it easier to use the function supplied by http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/. 

> **Note**:  I have adapted their code so that it does not conflict with `dplyr` code. So use the corrected functions I have supplied you otherwise if you are trying to use `dplyr` it will break (as this function requires the older `plyr` package. You will need to install `plyr` package, but do NOT load it). You have to be very careful when using the `plyr` and `dplyr` package at the same time. 

To use this function, you have to load the scripts (set the working directory where the file lives and `source` the file)

You can plot corrected +/- 1 SE or 95%CIs. Below is 95%CI. Compare them to the uncorrected 95% CI above.  The difference here is not massive,  

```{r,fig.width=6}
setwd("C:/AlexFiles/SugarSync/UIC/Teaching/Graduate/543-Fall2018/Week 9")
source('HelperFunctions.R')

MeansforGGPlot <- summarySEwithin(data=DataSim2, "Fixation", withinvars=c("Time","Reinforcement"),
                            idvar="ID", na.rm=FALSE, conf.interval=.95)

Means.Within.CI <-ggplot(data = MeansforGGPlot, aes(x = Time, y=Fixation, group=Reinforcement))+
  scale_y_continuous(breaks = seq(0,20,2))+
  geom_line(aes(colour = Reinforcement), size=2)+
  geom_ribbon(aes(ymin=Fixation-ci, ymax=Fixation+ci,fill = Reinforcement), alpha=.5)+
  ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "right")
Means.Within.CI
```


For within error bars (Corrected) you can eye-ball significance (Cumming & Finch, 2005)

95% CIs: 

-  $p < .05$: when proportion overlap is about .50
-  $p < .01$: when proportion overlap is about 0

### Within Errors Bars: SE

```{r,fig.width=6}
Means.Within.SE <-ggplot(data = MeansforGGPlot, aes(x = Time, y=Fixation, group=Reinforcement))+
  scale_y_continuous(breaks = seq(0,20,2))+
  geom_line(aes(colour = Reinforcement), size=2)+
  geom_ribbon(aes(ymin=Fixation-se, ymax=Fixation+se,fill = Reinforcement), alpha=.5)+
  ylab("Fixation (in Seconds)")+xlab("Time (in Minutes)")+
  theme(legend.position = "right")
Means.Within.SE
```

SE bars: 

-  $p < .05$: when proportion gap is 1x size of SE bar
-  $p < .01$: when proportion gap is 2x size of SE bar


# Follow Up Testing
Following up the main-effects and interactions are mostly the same as with two-way ANOVA. However, you have a few more decision to make based on how conservative you want to be. 

##  Modern approach 
- If yes, emmeans will use the correct error term from ANOVA automatically. The degrees of freedom are based on Satterthwaite approximations, which are more like between between-subjects DF but correcting for HOV. However, this does not control for violations of sphericity. So when have violations of sphericity, this approach is anti-conservative and can inflate type I error on follow-ups. 
    - You can apply an extra correction (HSD, MVT, Sidek, Holm, Bonferroni, etc.)
    - You can do any type of contrast you want

### Assume sphericity: Satterthwaite DF (Default)

#### Follow Up Interaction
Example using simple effects followed up by pairwise comparisons 

```{r}
library(emmeans)
Reinforcement.by.Time<-emmeans(Model.1,~Reinforcement|Time)
test(pairs(Reinforcement.by.Time), joint=TRUE)
```

Since we see only the middle two-time points had differences, we will examine the pairwise results

```{r}
pairs(Reinforcement.by.Time, adjust ='tukey')
```

#### Follow Up Main-effect
Tend analysis of Time
```{r}
Time.Main.Effect<-emmeans(Model.1,~Time)
contrast(Time.Main.Effect, 'poly')
```

### Assume Strong Violations of Sphericity: Multivariate Approach 

You can override this default and choose instead to do what SPSS does by default for contrasts: assume violations of sphericity. This uses a different approach (multivariate analysis) and uses smaller more conservative DF (we will not get into the details of univariate vs. multivariate testing yet). For a quick understanding: It assumes the data are NOT within-subject, but instead run a multivariate analysis of variance (MANOVA).  This is a much-less-powerful approach. 

#### MANOVA results

```{r}
Model.M<-aov_car(Fixation~ Time*Reinforcement + Error(ID/Time*Reinforcement), 
        data = DataSim2, return='Anova')
Model.M
```

What you can see the interaction is no longer significant at $p <.05$, so we would not follow it up. However, I will do so to show how the follow-ups change:    

#### Follow Up interaction
Example using simple effects followed up by pairwise comparisons 

```{r}
Reinforcement.by.Time.M<-emmeans(Model.1,~Reinforcement|Time,model = "multivariate")
test(pairs(Reinforcement.by.Time.M), joint=TRUE)
```

Since we see only the middle two-time points had differences, we will examine the pairwise results

```{r}
pairs(Reinforcement.by.Time.M, adjust ='tukey')
```

As you can see, these results are different from the univariate approach (RM ANOVA).

### Assume Strong Violations of Sphericity: Multivariate DF
Your book recommends another method assuming you do not want to use MANOVA approach for violations of sphericity.

- Don't use the errors term from the ANOVAs, run pairwise comparisons ONLY using paired t-tests
- Bonferroni correct the pairwise results [which can inflate Type II] 

The problem with this approach, you cannot do anything but pairwise analysis (**no contrasts of any kind**)

#### Follow-up Interaction

To test the interaction, you must first create a new term merging the Time X Reinforcement into 1 new variable. The term `with` temporarily attaches the data frame to make your code easier to understand. 

```{r}
DataSim2$ITerm <- with(DataSim2, interaction(Time,  Reinforcement), drop = TRUE )
```

using the `pairwise.t.test`, we pass it the arguments `paired=TRUE` and `p.adj = "bonf"` (Note: this is one family of tests, so $K=4*3=12$, thus $K(K-1)/2 = 66$. Thus $a_{bon} = .05 / 66 = 0.00075$  

```{r}
with(DataSim2, 
     pairwise.t.test(Fixation,ITerm,paired=TRUE,p.adj = "bonf"))
```

#### Follow-up Main effect
If you wanted to follow up the main-effect, just call that variable (Note: this will only correct for 6 tests as this is one family)

```{r}
with(DataSim2, 
     pairwise.t.test(Fixation,Time,paired=TRUE,p.adj = "bonf"))
```


# Guidelines

- Graph your results with the corrected error bars and try to look at spaghetti plots as well. This is MOST important thing you can do in a repeated measure design. You will see the violations of your assumptions, and this will guide your selection of an approach for follow-up testing. You will see bad subjects, conditions, or interactions between subjects and conditions. This way when understanding how your ANOVA will parse your variance. 

- Design RM studies with tend analyses in mind (think ordinally when possible). When this is not possible make sure to limit the number of levels you will examine. Each level you add the more chance to violate sphericity and inflate Type I error. 

 
## Follow-Ups: 

- When you use the modern methods, you must report which packages you use in your method section.
- Apply alpha correction and use a more conservative approach over the between-subjects test. 
- If you use the Old-school method: Avoid using the error term from the RM ANOVA for pairwise testing. 
    - Yes, it buys power, but at a large cost of Type I error.    
        - Do as few tests as you can and thus Bonferroni corrections are not killing you power. 



# References
Bakeman, R. (2005). Recommended effect size statistics for repeated measures designs. *Behavior research methods*, 37(3), 379-384.

Cousineau, D., & O'Brien, F. (2014). Error bars in within-subject designs: a comment on Baguley (2012). *Behavior Research Methods*, 46(4), 1149-1151.

Olejnik, S., & Algina, J. (2003). Generalized eta and omega squared statistics: Measures of effect size for some common research designs. *Psychological Methods*, 8(4), 434-447. doi:10.1037/1082-989X.8.4.434
